
# Lectures

Lecture's content and syllabus

&#x1F4D1;  Lecture 1: Introduction [Oct. 6]Page

&#x1F4D1;  Lecture 2: Linear Models for Regression [Oct 13]Page

&#x1F4D1;  Lecture 3: Linear Classifiers: LDA & Logistic Regression [Oct 18]Page

&#x1F4D1;  Lecture 4: Gradient Descent [Oct 27]Page

&#x1F4D1;  Lecture 5: The Perceptron & Bias-Variance Decomposition [Nov 10]Page

&#x1F4D1;  Lecture 6: Support Vector Machines & Kernels [Nov 17]Page

&#x1F4D1;  Lecture 7: Kernels [Nov 24]Page

&#x1F4D1;  Lecture 8: Kernels (cont), Bias-variance decomposition and regularization [Dec 1]Page

&#x1F4D1;  Lecture 9: Regularization, Validation & Trees (Part I) [Dec 8]


# References

```math
\begin{gather}
\phi(u) = [u_i^2, \sqrt(2Cu_1), c]^T
\\
\phi(v) = [v_i^2, \sqrt(2Cv_1), c]^T
\\
\phi(u)^T\phi(v) = u_i^2 v_i^2 + 2cu_iv_i + c^2
\end{gather}
```
