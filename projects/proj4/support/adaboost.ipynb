{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d44931-9621-4763-a3e7-86be62ce9858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adaboost (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DecisionTree\n",
    "using Random\n",
    "using Statistics: mean\n",
    "using CategoricalArrays\n",
    "\n",
    "# Define the AdaBoost algorithm\n",
    "function adaboost(X, y, T)\n",
    "    n, m = size(X)\n",
    "    \n",
    "    # Initialize weights\n",
    "    weights = ones(n) / n\n",
    "    \n",
    "    # Storage for weak classifiers, their weights, and alpha values\n",
    "    weak_classifiers = Vector{typeof(DecisionTreeClassifier)}(undef, T)\n",
    "    classifier_weights = zeros(T)\n",
    "    alphas = zeros(T)\n",
    "    \n",
    "    for t in 1:T\n",
    "        # Train a weak learner (decision stump in this case)\n",
    "        weak_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "        fit!(weak_classifier, X, categorical(y), sample_weights=weights)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = DecisionTree.predict(weak_classifier, X)\n",
    "        \n",
    "        # Calculate error\n",
    "        err = sum(weights .* (y .!= y_pred))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        err = max(err, eps())\n",
    "        \n",
    "        # Calculate classifier weight and alpha\n",
    "        beta = err / (1 - err)\n",
    "        alpha = log(1 / beta)\n",
    "        \n",
    "        # Update weights\n",
    "        weights *= exp(alpha * (y .!= y_pred))\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights /= sum(weights)\n",
    "        \n",
    "        # Store weak classifier, its weight, and alpha\n",
    "        weak_classifiers[t] = weak_classifier\n",
    "        classifier_weights[t] = alpha\n",
    "        alphas[t] = alpha\n",
    "    end\n",
    "    \n",
    "    return weak_classifiers, classifier_weights, alphas\n",
    "end\n",
    "\n",
    "# # Rest of the code remains the same\n",
    "\n",
    "# # Test the AdaBoost model on a new example\n",
    "# new_example = [7.0 8.0]\n",
    "# prediction = adaboost(weak_classifiers, classifier_weights, alphas, new_example)\n",
    "\n",
    "# println(\"AdaBoost Prediction for $new_example: \", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e5cd07-b5ba-46b0-89df-b167f4bfd779",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching fit!(::DecisionTreeClassifier, ::Matrix{Float64}, ::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}}; sample_weights::Vector{Float64})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  fit!(::DecisionTreeClassifier, ::Any, ::Any)\u001b[91m got unsupported keyword argument \"sample_weights\"\u001b[39m\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDecisionTree\u001b[39m \u001b[90m~/.julia/packages/DecisionTree/0Dw1P/src/\u001b[39m\u001b[90m\u001b[4mscikitlearnAPI.jl:91\u001b[24m\u001b[39m\n\u001b[0m  fit!(\u001b[91m::AdaBoostStumpClassifier\u001b[39m, ::Any, ::Any)\u001b[91m got unsupported keyword argument \"sample_weights\"\u001b[39m\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDecisionTree\u001b[39m \u001b[90m~/.julia/packages/DecisionTree/0Dw1P/src/\u001b[39m\u001b[90m\u001b[4mscikitlearnAPI.jl:518\u001b[24m\u001b[39m\n\u001b[0m  fit!(\u001b[91m::DecisionTreeRegressor\u001b[39m, ::AbstractMatrix, ::AbstractVector)\u001b[91m got unsupported keyword argument \"sample_weights\"\u001b[39m\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDecisionTree\u001b[39m \u001b[90m~/.julia/packages/DecisionTree/0Dw1P/src/\u001b[39m\u001b[90m\u001b[4mscikitlearnAPI.jl:208\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching fit!(::DecisionTreeClassifier, ::Matrix{Float64}, ::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}}; sample_weights::Vector{Float64})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  fit!(::DecisionTreeClassifier, ::Any, ::Any)\u001b[91m got unsupported keyword argument \"sample_weights\"\u001b[39m\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDecisionTree\u001b[39m \u001b[90m~/.julia/packages/DecisionTree/0Dw1P/src/\u001b[39m\u001b[90m\u001b[4mscikitlearnAPI.jl:91\u001b[24m\u001b[39m\n\u001b[0m  fit!(\u001b[91m::AdaBoostStumpClassifier\u001b[39m, ::Any, ::Any)\u001b[91m got unsupported keyword argument \"sample_weights\"\u001b[39m\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDecisionTree\u001b[39m \u001b[90m~/.julia/packages/DecisionTree/0Dw1P/src/\u001b[39m\u001b[90m\u001b[4mscikitlearnAPI.jl:518\u001b[24m\u001b[39m\n\u001b[0m  fit!(\u001b[91m::DecisionTreeRegressor\u001b[39m, ::AbstractMatrix, ::AbstractVector)\u001b[91m got unsupported keyword argument \"sample_weights\"\u001b[39m\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDecisionTree\u001b[39m \u001b[90m~/.julia/packages/DecisionTree/0Dw1P/src/\u001b[39m\u001b[90m\u001b[4mscikitlearnAPI.jl:208\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] adaboost(X::Matrix{Float64}, y::Vector{Int64}, T::Int64)",
      "   @ Main ./In[4]:21",
      " [2] top-level scope",
      "   @ In[5]:8"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Generate synthetic data\n",
    "Random.seed!(123)\n",
    "X = randn(100, 2)\n",
    "y = rand([-1, 1], 100)\n",
    "\n",
    "# Train AdaBoost\n",
    "weak_classifiers, classifier_weights, alphas = adaboost(X, y, 50)\n",
    "\n",
    "# Test the AdaBoost model on a new example\n",
    "new_example = [0.5, 1.0]\n",
    "prediction = adaboost(weak_classifiers, classifier_weights, alphas, new_example)\n",
    "\n",
    "println(\"AdaBoost Prediction for $new_example: \", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdca424-1692-494c-9630-9e8c93ff3c55",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- [ ] [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n",
    "- [ ] [[05x06] DecisionTree.jl: Decision Tree, Random Forest, AdaBoost | Julia Supervised Machine Learning](https://www.youtube.com/watch?v=XTApO31m3Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50e5d7-40b4-48bb-9603-b393907f321f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
