{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7761bcc2-3b20-4647-b658-452d6bab4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, MLDatasets, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299b0b2b-d54d-465c-b545-953637a2651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: onehotbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5997a295-2286-42da-a23c-4798aa8f58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5a220e9-3859-4618-9393-a6538cec4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Array{UInt8}} with 6 entries:\n",
       "  \"train_labels\" => [0x07; 0x03; … ; 0x06; 0x04;;]\n",
       "  \"test_labels\"  => [0x03; 0x00; … ; 0x01; 0x07;;]\n",
       "  \"val_labels\"   => [0x04; 0x00; … ; 0x01; 0x06;;]\n",
       "  \"test_images\"  => [0xe8 0xe5 … 0xac 0xaf; 0xef 0xe3 … 0xb6 0xb8; … ; 0xe1 0xd…\n",
       "  \"val_images\"   => [0xff 0xff … 0xc3 0xb9; 0xff 0xe7 … 0xfe 0xea; … ; 0xca 0xc…\n",
       "  \"train_images\" => [0xfa 0xff … 0xd7 0xd9; 0xff 0xfd … 0xfe 0xfe; … ; 0xcd 0xc…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = npzread(\"data/bloodmnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d6c1e3-d27c-4956-aa37-23f6dda101a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Float64.(imgs[1:4]), typeof(imgs), size(imgs)) = ([250.0, 255.0, 185.0, 226.0], Array{UInt8, 4}, (11959, 28, 28, 3))\n"
     ]
    }
   ],
   "source": [
    "imgs = dataset[\"train_images\"]; @show Float64.(imgs[1:4]), typeof(imgs), size(imgs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78032388-1931-48a0-833c-673fa125cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cda4be2c-71f3-4ca1-8f61-b226469aad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ImageView  # Packages for image handling and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eef67781-b75a-47e7-a180-0b387f89c6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_montage (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `train_dataset` is an array of images\n",
    "function create_montage(images, length)\n",
    "    # This is a simple example where we take the first `length` images and concatenate them\n",
    "    # In a real-world scenario, you would handle resizing and arranging the images as needed\n",
    "    hcat(images[1:length]...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ba589d9-e10a-4340-8364-93181d70c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 11950; img = Float32.(imgs[index, :, :, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b202cbbe-3f3d-43f8-a107-f3d08d9185d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 4 entries:\n",
       "  \"gui\"         => Dict{String, Any}(\"window\"=>GtkWindowLeaf(accessible-role=GT…\n",
       "  \"roi\"         => Dict{String, Any}(\"redraw\"=>ObserverFunction[ObserverFunctio…\n",
       "  \"annotations\" => Observable(Dict{UInt64, Any}())\n",
       "  \"clim\"        => Observable(CLim{Float32}(180.0, 224.0))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a montage of the training dataset images (length=1 implies a single image)\n",
    "# This part is highly dependent on the specific visualization functions available in Julia\n",
    "montage = create_montage(img, 28)\n",
    "\n",
    "# Visualize the montage\n",
    "imshow(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa894538-b539-4b89-93ef-b560c4431916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAALBJREFUaAW9wTEBAAAAgyAP+1feWgiOlsQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISOxlUAsC1d8RzAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAALBJREFUaAW9wTEBAAAAgyAP+1feWgiOlsQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISk5jEJCYxiUlMYhKTmMQkJjGJSUxiEpOYxCQmMYlJTGISOxlUAsC1d8RzAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float32}, ::Matrix{Float32}) with eltype Gray{Float32}:\n",
       " Gray{Float32}(181.0)  Gray{Float32}(184.0)  …  Gray{Float32}(230.0)\n",
       " Gray{Float32}(180.0)  Gray{Float32}(190.0)     Gray{Float32}(230.0)\n",
       " Gray{Float32}(187.0)  Gray{Float32}(203.0)     Gray{Float32}(230.0)\n",
       " Gray{Float32}(199.0)  Gray{Float32}(212.0)     Gray{Float32}(230.0)\n",
       " Gray{Float32}(199.0)  Gray{Float32}(204.0)     Gray{Float32}(227.0)\n",
       " Gray{Float32}(191.0)  Gray{Float32}(189.0)  …  Gray{Float32}(223.0)\n",
       " Gray{Float32}(196.0)  Gray{Float32}(191.0)     Gray{Float32}(216.0)\n",
       " Gray{Float32}(209.0)  Gray{Float32}(207.0)     Gray{Float32}(211.0)\n",
       " Gray{Float32}(210.0)  Gray{Float32}(214.0)     Gray{Float32}(209.0)\n",
       " Gray{Float32}(214.0)  Gray{Float32}(217.0)     Gray{Float32}(214.0)\n",
       " Gray{Float32}(217.0)  Gray{Float32}(220.0)  …  Gray{Float32}(224.0)\n",
       " Gray{Float32}(216.0)  Gray{Float32}(218.0)     Gray{Float32}(230.0)\n",
       " Gray{Float32}(211.0)  Gray{Float32}(213.0)     Gray{Float32}(230.0)\n",
       " ⋮                                           ⋱  \n",
       " Gray{Float32}(212.0)  Gray{Float32}(213.0)     Gray{Float32}(228.0)\n",
       " Gray{Float32}(216.0)  Gray{Float32}(217.0)     Gray{Float32}(223.0)\n",
       " Gray{Float32}(204.0)  Gray{Float32}(200.0)     Gray{Float32}(203.0)\n",
       " Gray{Float32}(201.0)  Gray{Float32}(192.0)     Gray{Float32}(185.0)\n",
       " Gray{Float32}(214.0)  Gray{Float32}(206.0)  …  Gray{Float32}(187.0)\n",
       " Gray{Float32}(212.0)  Gray{Float32}(208.0)     Gray{Float32}(195.0)\n",
       " Gray{Float32}(208.0)  Gray{Float32}(205.0)     Gray{Float32}(201.0)\n",
       " Gray{Float32}(221.0)  Gray{Float32}(212.0)     Gray{Float32}(206.0)\n",
       " Gray{Float32}(224.0)  Gray{Float32}(225.0)     Gray{Float32}(201.0)\n",
       " Gray{Float32}(217.0)  Gray{Float32}(218.0)  …  Gray{Float32}(201.0)\n",
       " Gray{Float32}(209.0)  Gray{Float32}(208.0)     Gray{Float32}(197.0)\n",
       " Gray{Float32}(203.0)  Gray{Float32}(201.0)     Gray{Float32}(191.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view training input\n",
    "\n",
    "index = 11950; img = Float32.(imgs[index, :, :, 2])\n",
    "\n",
    "# use the ' transpose sign to invert the image\n",
    "\n",
    "colorview(Gray, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "277fb014-b27c-478e-9540-e370955f972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(imgs[1:4], typeof(imgs)) = (Float32[250.0, 255.0, 185.0, 226.0], Array{Float32, 4})\n"
     ]
    }
   ],
   "source": [
    "# Extract images and labels\n",
    "imgs = Float32.(dataset[\"train_images\"]); @show imgs[1:4], typeof(imgs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b57c71eb-5835-4aac-a844-e66170d9db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7fd7702d-d9fd-450c-a9c6-7a3a47986a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2539ce9c-4908-40fd-bb3a-e003f0708658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(typeof(img[:, :, index]), typeof(img)) = (Matrix{Float32}, Array{Float32, 3})\n"
     ]
    }
   ],
   "source": [
    "img = imgs[:,:,:,index]; @show typeof(img[:,:,index]), typeof(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cb4e37b8-c24b-4fc0-83ca-9f88c580c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorview( Gray, img[:,:,index]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "47becdcb-40ed-416f-91d9-49af0e1d5f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lbls[1:4], typeof(lbls), length(labels)) = (UInt8[0x07, 0x03, 0x06, 0x06], Matrix{UInt8}, 11959)\n"
     ]
    }
   ],
   "source": [
    "labels = dataset[\"train_labels\"]; @show lbls[1:4], typeof(lbls), length(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a41fcf1c-d04f-477f-82b7-cfd8d30df281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11959"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nTrain = length(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "da3e75d3-7685-4192-a335-b9347d89062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9b41a3df-400b-49da-9c11-d43ecf24396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.102 ms (83215 allocations: 2.32 MiB)\n"
     ]
    }
   ],
   "source": [
    "@btime trainData = vcat([hcat(float.(imgs[i])...)  for i in 1:nTrain]...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a1fad7da-d4a1-4438-a70c-67bde34159a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(typeof(trainData), length(trainData)) = (Matrix{Float64}, 28127568)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Matrix{Float64}, 28127568)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show typeof(trainData), length(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "33d5a05a-a987-43f5-a100-7ee77d34c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = labels[1:nTrain];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828340f-5d89-458d-ab33-9fa57a4f46a7",
   "metadata": {},
   "source": [
    "# References\n",
    "- [ ] [MedMNIST v2 - A large-scale lightweight benchmark\n",
    "for 2D and 3D biomedical image classification](https://arxiv.org/pdf/2110.14795.pdf)\n",
    "| Name | Source | Data  Modality | Task (# Classes / Labels) | # Samples | # Training / Validation / Test |\n",
    "|-|-|-|-|-|-|\n",
    "| BloodMNIST  | Acevedo et al. |  Blood Cell Microscope | MC (8) | 17,092  | 11,959 / 1,712 / 3,421 |\n",
    "- [ ] [\\[05x08\\] Intro to Artificial Neural Networks with Flux.jl (1 of 2); Julia Supervised Machine Learning](https://www.youtube.com/watch?v=zmlulaxatRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21981402-3a5e-476c-9872-823b9e4219d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
