{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18e8487-78b0-487e-b6de-c06cf7c9e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fd0d60-8a3b-4204-885a-d8ca8e20d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "train_x, train_y = MLDatasets.MNIST(split=:train)[:];\n",
    "test_x, test_y = MLDatasets.MNIST(split=:test)[:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536ede1c-34cd-4441-958b-22a540a3078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images and normalize pixel values\n",
    "flatten(x) = reshape(x, 28 * 28) / 255.0\n",
    "train_data = [(flatten(train_x[:, :, i]), train_y[i] + 1) for i in 1:size(train_x, 3)];\n",
    "test_data = [(flatten(test_x[:, :, i]), test_y[i] + 1) for i in 1:size(test_x, 3)];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82e0198-f456-480c-87e8-f8237e235662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"perceptron.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2082b2e4-ee7f-40b9-8153-e00e04dc3056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perceptron_model (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function perceptron_model(input_size)\n",
    "    weights = randn(input_size)\n",
    "    bias = randn()\n",
    "    return Perceptron(weights, bias)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b45b020-0708-45bb-b623-88587f98326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_perceptron! (generic function with 3 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the perceptron model\n",
    "function train_perceptron!(model, train_data, epochs = 10, lr = 0.1)\n",
    "    for epoch in 1:epochs\n",
    "        for (x, y) in train_data\n",
    "            ŷ = predict(model, x)\n",
    "            error = y - ŷ\n",
    "            \n",
    "            # Update weights and bias\n",
    "            model.weights .+= lr * error * x\n",
    "            model.bias += lr * error\n",
    "        end\n",
    "        println(\"Epoch $epoch\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd906a8d-ea9d-4a0f-b929-92fae264f9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_perceptron (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the perceptron model\n",
    "function test_perceptron(model, test_data)\n",
    "    correct = 0\n",
    "    total = length(test_data)\n",
    "\n",
    "    for (x, y) in test_data\n",
    "        ŷ = predict(model, x)\n",
    "        correct += ŷ == y ? 1 : 0\n",
    "    end\n",
    "\n",
    "    accuracy = correct / total\n",
    "    println(\"Test Accuracy: $accuracy\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edf5ff04-8b2d-46aa-aacc-95ca77c273b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n"
     ]
    }
   ],
   "source": [
    "# Create and train the perceptron model\n",
    "input_size = 28 * 28\n",
    "perceptron = perceptron_model(input_size)\n",
    "train_perceptron!(perceptron, train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8efdf692-0411-450c-9c37-b4ae2ccaf899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "# Test the trained perceptron\n",
    "test_perceptron(perceptron, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c264de-e5a0-442a-b2f2-26cb705f0693",
   "metadata": {},
   "source": [
    "## To improve the perceptron's accuracy, you can consider implementing the following enhancements:\n",
    "\n",
    "1. **Use a More Complex Model:** Single-layer perceptrons have limitations in handling complex patterns. Consider using a multi-layer perceptron (MLP) or other more advanced neural network architectures.\n",
    "\n",
    "2. **Normalization:** Normalize input data to ensure features have similar scales. This can help improve convergence and accuracy.\n",
    "\n",
    "3. **Learning Rate and Epochs:** Experiment with different learning rates and the number of training epochs to find values that improve convergence without overfitting.\n",
    "\n",
    "4. **Batch Training:** Instead of updating weights after each data point, consider using batches of data for updates. This can improve convergence and generalization.\n",
    "\n",
    "5. **Activation Function:** Try different activation functions like ReLU, sigmoid, or tanh. The choice of activation function can significantly impact performance.\n",
    "\n",
    "6. **Weight Initialization:** Proper initialization of weights can speed up convergence. Common methods include Xavier/Glorot initialization or He initialization.\n",
    "\n",
    "7. **Regularization:** Implement regularization techniques such as L1 or L2 regularization to prevent overfitting.\n",
    "\n",
    "8. **Data Augmentation:** Increase the size of your training dataset by applying transformations like rotations, flips, or slight translations to the images.\n",
    "\n",
    "9. **Dropout:** Introduce dropout layers during training to prevent overfitting by randomly dropping a fraction of neurons.\n",
    "\n",
    "10. **Optimizers:** Experiment with different optimization algorithms, such as Adam, SGD with momentum, or RMSprop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c71a56-1361-47c6-9ce2-66d7691d0e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
